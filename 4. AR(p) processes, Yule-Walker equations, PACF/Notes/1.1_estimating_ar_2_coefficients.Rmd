---
title: "Estimating AR(2) coefficients"
---

We want to estimate the estimate coefficients for the following $AR(2)$:

$$
X_t = Z_t + \phi_1 X_{t-1} + \phi_2 X_{t-2} \\
Z_t \sim Normal(\mu, \sigma_Z^2)
$$

### Estimating sigma

We can estimate the value of $\sigma_Z^2$. Given properties of variance, the variance of the sum of two random variables is:

$$
Var[aX + bY] = a^2 Var[X] + b^2 Var[Y] + 2ab \ Cov(X, Y)
$$

Then, we take the variance at both sides of the process:

$$
Var[X_t] = \sigma_Z^2 + \phi_1^2 Var[X_{t-1}] + \phi_2^2 Var[X_{t-2}] + 2 \phi_1 \phi_2 \ Cov(X_{t-1}, X_{t-2})
$$

Since:

 - $Var[X_i]$ is the autocovariance at lag 0 (i.e. $\gamma(0)$).
 - $\gamma(k) = Cov(X_t, X_{t+k})$, so $Cov(X_{t-1}, X_{t-2}) = \gamma(1)$.
 
Then we can write:

$$
\sigma_Z^2 = \gamma(0)  - \phi_1^2 \gamma(0) - \phi_2^2 \gamma(0) - 2 \phi_1 \phi_2 \gamma(1) \\
\sigma_Z^2 = \gamma(0)\left(1 - \phi_1^2 - \phi_2^2 - \frac{2 \phi_1 \phi_2 \gamma(1)}{\gamma{0}} \right) \\
\sigma_Z^2 = \gamma(0)\left(1 - \phi_1^2 - \phi_2^2 - 2 \phi_1 \phi_2 \rho(1) \right)
$$

From the matrix Yule-Walker equations, we have:


$$
\begin{bmatrix}
\rho(1) \\
\rho(2) 
\end{bmatrix} = 
\begin{bmatrix}
1 & \rho(1)  \\
\rho(1) & 1  \\
\end{bmatrix}
\begin{bmatrix}
\phi_1 \\
\phi_2
\end{bmatrix}
$$

And we can express the following:

$$
\rho(1) = \phi_1 + \rho(1)\phi_2 \implies \phi_1 = \rho(1) (1 - \phi_2) \\
\rho(2) = \rho(1) \phi_1 + \phi_2 \implies \phi_2 = \rho(1) (1 - \phi_1)
$$

If we go back to the equation of $\sigma_Z^2$ and we use the previous equalities, we can get a clearer formula for it:

$$
\sigma_Z^2 = \gamma(0)\left(1 - \phi_1^2 - \phi_2^2 - 2 \phi_1 \phi_2 \rho(1) \right) \\
\sigma^2_Z = \gamma(0) (1 - \phi_1^2 - \phi_2^2 - \phi_1 \phi_2 \rho(1) - \phi_1 \phi_2 \rho(1)) \\ 
\sigma^2_Z = \gamma(0)(1 - \phi_1(\phi_1 + \rho(1) \phi_2) - \phi_2Â² - \phi_1 \rho(1) \phi_2) \\
\sigma^2_Z = \gamma(0)(1 - \phi_1 \rho(1) - \phi_2 (\phi_2 + \rho(1) \phi_1 )) \\
\sigma^2_Z = \gamma(0)(1 - \phi_1 \rho(1) - \phi_2 \rho(2)) \\
$$

For a realization of the process (i.e. a time series), we can get the estimate $\hat{\sigma}^2_Z$ as:

$$
\hat{\sigma}^2_Z = c_0 (1 - \hat{\phi}_1 r_1 - \hat{\phi}_2 r_2) \\
\hat{\sigma}^2_Z = c_0 (1 - \hat{b}^{\top}\hat{\phi})
$$

Where:

- $c_0$ is the autocovariance estimate at lag $0$, which can be obtained through the `acf` command.
- $r_i$ are the sample autocorrelation functions, which can also be obtained using `acf`.
- $\hat{\phi}_i$ are the estimates of the $AR$ coefficients, which can be obtained through the Yule-Walker equations.


### Estimating AR coefficients in R

We are going to work with the following $AR(2)$ model:

$$
X_t = Z_t + \frac{1}{3} X_{t-1} + \frac{1}{2} X_{t-2} \\
Z_t \sim Normal(0, 4^2)
$$

Let's generathe the $AR$ process:

```{r}
n <- 10000
sigma <- 4
phi <- c(1/3, 1/2)
set.seed(2017)
ar.process <- arima.sim(n, model=list(ar=phi), sd=4)
```

Now, let's compute $r_1$ and $r_2$:

```{r}
# Note position 1 is r_0
r <- matrix(acf(ar.process, plot=FALSE)$acf[2:3], 1, 2)
```

Let's now build the proper matrices in order to solve:

$$
\hat{b} = \hat{R}\hat{\phi} \\
\begin{bmatrix}
r_1 \\
r_2 
\end{bmatrix} = 
\begin{bmatrix}
1 & r_1  \\
r_1 & 1  \\
\end{bmatrix}
\begin{bmatrix}
\hat{\phi_1} \\
\hat{\phi_2}
\end{bmatrix}
$$

Let's start with $\hat{b}$:

```{r}
# Use data from r
b <- matrix(r, 2, 1)
```

We can build $\hat{R}$ as:

```{r}
# Initialize matrix with ones
R <- matrix(1, 2, 2)
# Fill non-diagonal entries
R[1, 2] <- r[1]
R[2, 1] <- r[1]
```


Now let's solve for $\hat{\phi}$:

```{r}
phi.hat <- matrix(solve(R, b), 2, 1)
phi.hat
```

We confirm that the estimated coefficients are slighly close to the real ones (i.e. $\hat{\phi}_i \approx \phi_i$) and should get closer to the real ones as we increase the number of points.

Let's solve now for $\hat{\sigma_Z^2}$:

```{r}
c0 <- acf(ar.process, type = 'covariance', plot = FALSE)$acf[1]
var.hat <- c0 * (1 - t(b) %*% phi.hat)
var.hat
```

We confirm estimate variance is close to the variance of the generating process.
